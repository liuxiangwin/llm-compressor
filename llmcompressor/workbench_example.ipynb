{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Compressor Workbench -- Getting Started\n",
    "\n",
    "This notebook will demonstrate how common [LLM Compressor](https://github.com/vllm-project/llm-compressor) flows can be run on the [opendatahub/llmcompressor-workbench](https://quay.io/repository/opendatahub/llmcompressor-workbench) image.\n",
    "\n",
    "We will show how a user can compress and evaluate a Large Language Model, first without data and then with a calibration dataset.\n",
    "\n",
    "The notebook will detect if a GPU is available. If one is not available, it will demonstrate an abbreviated run, so users without GPU access can still get a feel for `llm-compressor`.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> If you are not using the Workbench image, just be sure to have lm_eval>=0.4.8 and llmcompressor>=0.5.1 installed\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1\\) Data-Free Model Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "codeflare-sdk 0.26.0 requires pydantic<2, but you have pydantic 2.11.7 which is incompatible.\n",
      "codeflare-sdk 0.26.0 requires ray[data,default]==2.35.0, but you have ray 2.47.0 which is incompatible.\n",
      "kfp 2.9.0 requires protobuf<5,>=4.21.1, but you have protobuf 5.29.5 which is incompatible.\n",
      "kfp-kubernetes 1.4.0 requires protobuf<5,>=4.21.1, but you have protobuf 5.29.5 which is incompatible.\n",
      "kfp-pipeline-spec 0.4.0 requires protobuf<5,>=4.21.1, but you have protobuf 5.29.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install llmcompressor lm-eval vllm --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install -qU transformers  --quiet\n",
    "!pip install transformers==4.51.3 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import modeling_utils\n",
    "if not hasattr(modeling_utils, \"ALL_PARALLEL_STYLES\") or modeling_utils.ALL_PARALLEL_STYLES is None:\n",
    "    modeling_utils.ALL_PARALLEL_STYLES = [\"tp\", \"none\",\"colwise\",'rowwise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmcompressor.modifiers.quantization import QuantizationModifier\n",
    "\n",
    "# model to compress\n",
    "model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "\n",
    "# This recipe will quantize all Linear layers except those in the `lm_head`,\n",
    "#  which is often sensitive to quantization. The W4A16 scheme compresses\n",
    "#  weights to 4-bit integers while retaining 16-bit activations.\n",
    "recipe = QuantizationModifier(\n",
    "    targets=\"Linear\", scheme=\"W4A16\", ignore=[\"lm_head\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up model using huggingface API\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, \n",
    "    device_map=\"auto\", \n",
    "    torch_dtype=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:51:06.156422+0000 | reset | INFO - Compression lifecycle reset\n",
      "2025-06-17T06:51:06.157677+0000 | from_modifiers | INFO - Creating recipe from modifiers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manager stage: Modifiers initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:51:07.647286+0000 | initialize | INFO - Compression lifecycle initialized for 1 modifiers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manager stage: Modifiers finalized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:51:07.648231+0000 | finalize | INFO - Compression lifecycle finalized for 1 modifiers\n",
      "2025-06-17T06:51:07.648731+0000 | post_process | WARNING - Optimized model is not saved. To save, please provide`output_dir` as input arg.Ex. `oneshot(..., output_dir=...)`\n"
     ]
    }
   ],
   "source": [
    "# Run compression using `oneshot`\n",
    "from llmcompressor import oneshot\n",
    "\n",
    "model = oneshot(model=model, recipe=recipe, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:51:07.652938+0000 | save_pretrained_wrapper | INFO - Fetching state_dict - this may take some time\n",
      "2025-06-17T06:51:09.191813+0000 | save_pretrained_wrapper | INFO - Fetching compressor\n",
      "2025-06-17T06:51:09.192585+0000 | get_model_compressor | INFO - skip_sparsity_compression_stats set to True. Skipping sparsity compression statistic calculations. No sparsity compressor will be applied.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Quantized Compression: 100%|██████████| 509/509 [00:04<00:00, 110.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:51:13.793994+0000 | save_pretrained_wrapper | INFO - Saving compressed model to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Save model and tokenizer\n",
    "model_dir = \"./\" + model_id.split(\"/\")[-1] + \"-W4A16\"\n",
    "model.save_pretrained(model_dir)\n",
    "tokenizer.save_pretrained(model_dir);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2\\) Evaluate compressed model using open-source `lm_eval` framework\n",
    "\n",
    "We will evaluate the performance of the model on the [`wikitext`](https://paperswithcode.com/dataset/wikitext-2) language modeling dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-17 06:51:20 [__init__.py:243] Automatically detected platform cuda.\n",
      "INFO 06-17 06:51:22 [__init__.py:31] Available plugins for group vllm.general_plugins:\n",
      "INFO 06-17 06:51:22 [__init__.py:33] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver\n",
      "INFO 06-17 06:51:22 [__init__.py:36] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.\n",
      "INFO 06-17 06:51:31 [config.py:793] This model supports multiple tasks: {'score', 'embed', 'generate', 'reward', 'classify'}. Defaulting to 'generate'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.11/site-packages/llmcompressor/pytorch/__init__.py:19: UserWarning: torch.compile is not supported by llmcompressor for torch 2.0.x\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-17 06:51:32 [config.py:2118] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "WARNING 06-17 06:51:32 [utils.py:2531] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reason: CUDA is initialized\n",
      "INFO 06-17 06:51:37 [__init__.py:243] Automatically detected platform cuda.\n",
      "INFO 06-17 06:51:40 [core.py:438] Waiting for init message from front-end.\n",
      "INFO 06-17 06:51:40 [__init__.py:31] Available plugins for group vllm.general_plugins:\n",
      "INFO 06-17 06:51:40 [__init__.py:33] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver\n",
      "INFO 06-17 06:51:40 [__init__.py:36] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.\n",
      "INFO 06-17 06:51:40 [core.py:65] Initializing a V1 LLM engine (v0.9.0.1) with config: model='./TinyLlama-1.1B-Chat-v1.0-W4A16', speculative_config=None, tokenizer='./TinyLlama-1.1B-Chat-v1.0-W4A16', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=compressed-tensors, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=1234, served_model_name=./TinyLlama-1.1B-Chat-v1.0-W4A16, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\": 3, \"custom_ops\": [\"none\"], \"splitting_ops\": [\"vllm.unified_attention\", \"vllm.unified_attention_with_output\"], \"compile_sizes\": [], \"inductor_compile_config\": {\"enable_auto_functionalized_v2\": false}, \"use_cudagraph\": true, \"cudagraph_num_of_warmups\": 1, \"cudagraph_capture_sizes\": [512, 504, 496, 488, 480, 472, 464, 456, 448, 440, 432, 424, 416, 408, 400, 392, 384, 376, 368, 360, 352, 344, 336, 328, 320, 312, 304, 296, 288, 280, 272, 264, 256, 248, 240, 232, 224, 216, 208, 200, 192, 184, 176, 168, 160, 152, 144, 136, 128, 120, 112, 104, 96, 88, 80, 72, 64, 56, 48, 40, 32, 24, 16, 8, 4, 2, 1], \"max_capture_size\": 512}\n",
      "WARNING 06-17 06:51:41 [utils.py:2671] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f66abe19ad0>\n",
      "INFO 06-17 06:51:41 [parallel_state.py:1064] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "WARNING 06-17 06:51:41 [topk_topp_sampler.py:58] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 06-17 06:51:41 [gpu_model_runner.py:1531] Starting to load model ./TinyLlama-1.1B-Chat-v1.0-W4A16...\n",
      "INFO 06-17 06:51:41 [compressed_tensors_wNa16.py:94] Using MarlinLinearKernel for CompressedTensorsWNA16\n",
      "INFO 06-17 06:51:41 [cuda.py:217] Using Flash Attention backend on V1 engine.\n",
      "INFO 06-17 06:51:41 [backends.py:35] Using InductorAdaptor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  6.73it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  6.72it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-17 06:51:41 [default_loader.py:280] Loading weights took 0.18 seconds\n",
      "INFO 06-17 06:51:42 [gpu_model_runner.py:1549] Model loading took 0.7432 GiB and 0.398142 seconds\n",
      "INFO 06-17 06:51:48 [backends.py:459] Using cache directory: /opt/app-root/src/.cache/vllm/torch_compile_cache/e527347c1c/rank_0_0 for vLLM's torch.compile\n",
      "INFO 06-17 06:51:48 [backends.py:469] Dynamo bytecode transform time: 6.75 s\n",
      "INFO 06-17 06:51:51 [backends.py:158] Cache the graph of shape None for later use\n",
      "INFO 06-17 06:52:13 [backends.py:170] Compiling a graph for general shape takes 24.19 s\n",
      "INFO 06-17 06:52:25 [monitor.py:33] torch.compile takes 30.93 s in total\n",
      "INFO 06-17 06:52:26 [kv_cache_utils.py:637] GPU KV cache size: 839,248 tokens\n",
      "INFO 06-17 06:52:26 [kv_cache_utils.py:640] Maximum concurrency for 2,048 tokens per request: 409.79x\n",
      "INFO 06-17 06:52:49 [gpu_model_runner.py:1933] Graph capturing finished in 23 secs, took 0.37 GiB\n",
      "INFO 06-17 06:52:49 [core.py:167] init engine (profile, create kv cache, warmup model) took 67.01 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
      "[Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "[Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
      "[Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "[Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte\n",
      "[Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c88cb51e57fe4209a1fe786fa4f8258d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.76k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a4c9fecbcb42b59108747b9da100d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "wikitext-2-raw-v1/wikitext-2-raw-v1-trai(…):   0%|          | 0.00/6.18M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea74fc28057846d89b7861e2f28cbd89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "wikitext-2-raw-v1/wikitext-2-raw-v1-vali(…):   0%|          | 0.00/641k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d5cfd4483841dcabd4d7e672c14c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "wikitext-2-raw-v1/wikitext-2-raw-v1-test(…):   0%|          | 0.00/715k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b0cd3cddd94299965bc29d53a290df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/629 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d535741bce0148efa450fdfee8d13945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/60 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ab02cbed847405e84bdc9d2b5b4b2f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/62 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 724.90it/s]\n",
      "  0%|          | 0/62 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (5945 > 2048). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 62/62 [00:00<00:00, 101.30it/s]\n",
      "Running loglikelihood requests:   0%|          | 0/62 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb6b54f2dd640b0b1ceed6af26be8e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7378692d6d174721a1e954b769ef3397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/62 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running loglikelihood requests: 100%|██████████| 62/62 [00:05<00:00, 10.72it/s]\n",
      "Running loglikelihood requests:   0%|          | 0/62 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07dc4e722529434fa44788afe0006c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a91a94f28a74b48817e8311c4e48a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/62 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running loglikelihood requests: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]\n",
      "Running loglikelihood requests:   0%|          | 0/62 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4075b6891344381897d3b4bae4d253b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf158afef69748158d84c6e4edd71921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/62 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running loglikelihood requests: 100%|██████████| 62/62 [00:05<00:00, 11.01it/s]\n",
      "[rank0]:[W617 06:53:23.078732241 ProcessGroupNCCL.cpp:1476] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    }
   ],
   "source": [
    "import lm_eval\n",
    "from lm_eval.utils import make_table\n",
    "\n",
    "results = lm_eval.simple_evaluate(\n",
    "    model=\"vllm\" if use_gpu else \"hf\",\n",
    "    model_args={\n",
    "        \"pretrained\": model_dir,\n",
    "        \"add_bos_token\": True,\n",
    "        \"device\": \"auto\"\n",
    "    },\n",
    "    tasks=[\"wikitext\"],\n",
    "    batch_size=\"auto\" if use_gpu else 4,\n",
    "    limit=None if use_gpu else 4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Tasks  |Version|Filter|n-shot|    Metric     |   | Value |   |Stderr|\n",
      "|--------|------:|------|-----:|---------------|---|------:|---|------|\n",
      "|wikitext|      2|none  |     0|bits_per_byte  |↓  | 0.7583|±  |   N/A|\n",
      "|        |       |none  |     0|byte_perplexity|↓  | 1.6916|±  |   N/A|\n",
      "|        |       |none  |     0|word_perplexity|↓  |16.6245|±  |   N/A|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(make_table(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3\\) Calibrated Compression with a Dataset\n",
    "\n",
    "Some more advanced compression algorithms require a small dataset of calibration samples that are meant to be a representative random subset of the language the model will see at inference.\n",
    "\n",
    "We will show how the previous section can be augmented with a calibration dataset and GPTQ, one of the first published LLM compression algorithms.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> This will take several minutes if no GPU is available\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use a new recipe running GPTQ (https://arxiv.org/abs/2210.17323)\n",
    "# to reduce error caused by quantization. GPTQ requires a calibration dataset.\n",
    "from llmcompressor.modifiers.quantization import GPTQModifier\n",
    "\n",
    "recipe = GPTQModifier(targets=\"Linear\", scheme=\"W4A16\", ignore=[\"lm_head\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5cca271ee04419fb1cb07761cfa8f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Create the calibration dataset, using Huggingface datasets API\n",
    "dataset_id = \"HuggingFaceH4/ultrachat_200k\"\n",
    "\n",
    "# Select number of samples. 512 samples is a good place to start.\n",
    "# Increasing the number of samples can improve accuracy.\n",
    "num_calibration_samples = 512 if use_gpu else 4\n",
    "max_sequence_length = 2048 if use_gpu else 16\n",
    "\n",
    "# Load dataset\n",
    "ds = load_dataset(dataset_id, split=\"train_sft\")\n",
    "# Shuffle and grab only the number of samples we need\n",
    "ds = ds.shuffle(seed=42).select(range(num_calibration_samples))\n",
    "\n",
    "# Preprocess and tokenize into format the model uses\n",
    "def preprocess(example):\n",
    "    text = tokenizer.apply_chat_template(\n",
    "            example[\"messages\"],\n",
    "            tokenize=False,\n",
    "        )\n",
    "    return tokenizer(\n",
    "        text,\n",
    "        padding=False,\n",
    "        max_length=max_sequence_length,\n",
    "        truncation=True,\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    "\n",
    "ds = ds.map(preprocess, remove_columns=ds.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:53:28.626297+0000 | reset | INFO - Compression lifecycle reset\n",
      "2025-06-17T06:53:28.627428+0000 | from_modifiers | INFO - Creating recipe from modifiers\n",
      "2025-06-17T06:53:28.629109+0000 | _check_build_quant_modifier | WARNING - GPTQ quantization is set to True without an active quantization modifier.\n",
      "2025-06-17T06:53:28.629511+0000 | _build_quant_modifier | INFO - Building quantization modifier with args: {'targets': 'Linear', 'scheme': 'W4A16', 'ignore': ['lm_head']}\n",
      "2025-06-17T06:53:28.678451+0000 | _check_calibration_data | INFO - Skipping QuantizationModifier calibration, it is not required for the provided quantization config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing intermediates cache: 100%|██████████| 512/512 [00:01<00:00, 411.53it/s]\n",
      "(1/23): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 68.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:53:38.555433+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.0.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:53:39.554321+0000 | compress | METRIC - time 1.00s\n",
      "2025-06-17T06:53:39.555133+0000 | compress | METRIC - error 611.05\n",
      "2025-06-17T06:53:39.556127+0000 | compress | METRIC - GPU 0 | usage: 10.51% | total memory: 24 GB\n",
      "2025-06-17T06:53:39.556507+0000 | compress | METRIC - GPU 1 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:53:39.556886+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:53:39.557254+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:53:39.557638+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:53:39.558644+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.0.self_attn.k_proj using 512 samples\n",
      "2025-06-17T06:53:40.514340+0000 | compress | METRIC - time 0.96s\n",
      "2025-06-17T06:53:40.514954+0000 | compress | METRIC - error 595.48\n",
      "2025-06-17T06:53:40.515827+0000 | compress | METRIC - GPU 0 | usage: 10.51% | total memory: 24 GB\n",
      "2025-06-17T06:53:40.516178+0000 | compress | METRIC - GPU 1 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:53:40.516556+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:53:40.516912+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:53:40.517334+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:53:40.518304+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.0.self_attn.v_proj using 512 samples\n",
      "2025-06-17T06:53:41.493173+0000 | compress | METRIC - time 0.97s\n",
      "2025-06-17T06:53:41.494086+0000 | compress | METRIC - error 1.03\n",
      "2025-06-17T06:53:41.494884+0000 | compress | METRIC - GPU 0 | usage: 10.51% | total memory: 24 GB\n",
      "2025-06-17T06:53:41.495182+0000 | compress | METRIC - GPU 1 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:53:41.495562+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:53:41.495922+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:53:41.496289+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:53:41.497335+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.0.self_attn.o_proj using 512 samples\n",
      "2025-06-17T06:53:42.465321+0000 | compress | METRIC - time 0.97s\n",
      "2025-06-17T06:53:42.466075+0000 | compress | METRIC - error 0.05\n",
      "2025-06-17T06:53:42.466811+0000 | compress | METRIC - GPU 0 | usage: 10.51% | total memory: 24 GB\n",
      "2025-06-17T06:53:42.467158+0000 | compress | METRIC - GPU 1 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:53:42.467543+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:53:42.467896+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:53:42.468259+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:53:42.469233+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.0.mlp.gate_proj using 512 samples\n",
      "2025-06-17T06:53:43.421918+0000 | compress | METRIC - time 0.95s\n",
      "2025-06-17T06:53:43.422783+0000 | compress | METRIC - error 130.06\n",
      "2025-06-17T06:53:43.423548+0000 | compress | METRIC - GPU 0 | usage: 10.51% | total memory: 24 GB\n",
      "2025-06-17T06:53:43.423897+0000 | compress | METRIC - GPU 1 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:53:43.424260+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:53:43.424634+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:53:43.424987+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:53:43.425977+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.0.mlp.up_proj using 512 samples\n",
      "2025-06-17T06:53:44.404702+0000 | compress | METRIC - time 0.98s\n",
      "2025-06-17T06:53:44.405613+0000 | compress | METRIC - error 115.15\n",
      "2025-06-17T06:53:44.406389+0000 | compress | METRIC - GPU 0 | usage: 10.51% | total memory: 24 GB\n",
      "2025-06-17T06:53:44.406762+0000 | compress | METRIC - GPU 1 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:53:44.407100+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:53:44.407491+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:53:44.407864+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:53:44.408887+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.0.mlp.down_proj using 512 samples\n",
      "2025-06-17T06:53:47.156985+0000 | compress | METRIC - time 2.75s\n",
      "2025-06-17T06:53:47.158336+0000 | compress | METRIC - error 0.36\n",
      "2025-06-17T06:53:47.159197+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:53:47.159570+0000 | compress | METRIC - GPU 1 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:53:47.159939+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:53:47.160295+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:53:47.160767+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(1/23): Propagating: 100%|██████████| 512/512 [00:03<00:00, 157.42it/s]\n",
      "(2/23): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 69.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:53:57.825571+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.1.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:53:58.784352+0000 | compress | METRIC - time 0.96s\n",
      "2025-06-17T06:53:58.785354+0000 | compress | METRIC - error 1015.92\n",
      "2025-06-17T06:53:58.786185+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:53:58.786566+0000 | compress | METRIC - GPU 1 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:53:58.786964+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:53:58.787324+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:53:58.787708+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:53:58.788761+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.1.self_attn.k_proj using 512 samples\n",
      "2025-06-17T06:53:59.764259+0000 | compress | METRIC - time 0.98s\n",
      "2025-06-17T06:53:59.765235+0000 | compress | METRIC - error 806.08\n",
      "2025-06-17T06:53:59.766059+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:53:59.766529+0000 | compress | METRIC - GPU 1 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:53:59.766900+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:53:59.767243+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:53:59.767623+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:53:59.768674+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.1.self_attn.v_proj using 512 samples\n",
      "2025-06-17T06:54:00.752391+0000 | compress | METRIC - time 0.98s\n",
      "2025-06-17T06:54:00.753355+0000 | compress | METRIC - error 5.30\n",
      "2025-06-17T06:54:00.754133+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:54:00.754520+0000 | compress | METRIC - GPU 1 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:00.754884+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:00.755247+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:54:00.755685+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:54:00.756679+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.1.self_attn.o_proj using 512 samples\n",
      "2025-06-17T06:54:01.742020+0000 | compress | METRIC - time 0.98s\n",
      "2025-06-17T06:54:01.742999+0000 | compress | METRIC - error 0.53\n",
      "2025-06-17T06:54:01.743742+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:54:01.744094+0000 | compress | METRIC - GPU 1 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:01.744472+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:01.744824+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:54:01.745218+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:54:01.746202+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.1.mlp.gate_proj using 512 samples\n",
      "2025-06-17T06:54:02.736684+0000 | compress | METRIC - time 0.99s\n",
      "2025-06-17T06:54:02.737881+0000 | compress | METRIC - error 320.10\n",
      "2025-06-17T06:54:02.738651+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:54:02.739031+0000 | compress | METRIC - GPU 1 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:02.739377+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:02.739728+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:54:02.740129+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:54:02.741086+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.1.mlp.up_proj using 512 samples\n",
      "2025-06-17T06:54:03.710831+0000 | compress | METRIC - time 0.97s\n",
      "2025-06-17T06:54:03.711814+0000 | compress | METRIC - error 286.73\n",
      "2025-06-17T06:54:03.712615+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:54:03.712980+0000 | compress | METRIC - GPU 1 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:03.713356+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:03.713756+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:54:03.714156+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:54:03.715239+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.1.mlp.down_proj using 512 samples\n",
      "2025-06-17T06:54:06.354337+0000 | compress | METRIC - time 2.64s\n",
      "2025-06-17T06:54:06.355729+0000 | compress | METRIC - error 1.10\n",
      "2025-06-17T06:54:06.356522+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:54:06.356881+0000 | compress | METRIC - GPU 1 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:06.357282+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:06.357657+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:54:06.358043+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(2/23): Propagating: 100%|██████████| 512/512 [00:02<00:00, 181.81it/s]\n",
      "(3/23): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 69.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:54:16.583009+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.2.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:54:17.554434+0000 | compress | METRIC - time 0.97s\n",
      "2025-06-17T06:54:17.555433+0000 | compress | METRIC - error 821.41\n",
      "2025-06-17T06:54:17.556193+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:54:17.556564+0000 | compress | METRIC - GPU 1 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:17.556940+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:17.557316+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:54:17.557684+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:54:17.558715+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.2.self_attn.k_proj using 512 samples\n",
      "2025-06-17T06:54:18.532922+0000 | compress | METRIC - time 0.97s\n",
      "2025-06-17T06:54:18.533952+0000 | compress | METRIC - error 448.06\n",
      "2025-06-17T06:54:18.534795+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:54:18.535170+0000 | compress | METRIC - GPU 1 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:18.535539+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:18.535908+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:54:18.536277+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:54:18.537280+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.2.self_attn.v_proj using 512 samples\n",
      "2025-06-17T06:54:19.495327+0000 | compress | METRIC - time 0.96s\n",
      "2025-06-17T06:54:19.496203+0000 | compress | METRIC - error 9.94\n",
      "2025-06-17T06:54:19.496975+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:54:19.497321+0000 | compress | METRIC - GPU 1 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:19.497708+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:19.498027+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:54:19.498419+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:54:19.499451+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.2.self_attn.o_proj using 512 samples\n",
      "2025-06-17T06:54:20.447608+0000 | compress | METRIC - time 0.95s\n",
      "2025-06-17T06:54:20.448480+0000 | compress | METRIC - error 0.83\n",
      "2025-06-17T06:54:20.449269+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:54:20.449665+0000 | compress | METRIC - GPU 1 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:20.449987+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:20.450383+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:54:20.450769+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:54:20.451771+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.2.mlp.gate_proj using 512 samples\n",
      "2025-06-17T06:54:21.413082+0000 | compress | METRIC - time 0.96s\n",
      "2025-06-17T06:54:21.414226+0000 | compress | METRIC - error 580.72\n",
      "2025-06-17T06:54:21.415010+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:54:21.415378+0000 | compress | METRIC - GPU 1 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:21.415749+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:21.416106+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:54:21.416503+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:54:21.417503+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.2.mlp.up_proj using 512 samples\n",
      "2025-06-17T06:54:22.373635+0000 | compress | METRIC - time 0.96s\n",
      "2025-06-17T06:54:22.374540+0000 | compress | METRIC - error 512.12\n",
      "2025-06-17T06:54:22.375289+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:54:22.375828+0000 | compress | METRIC - GPU 1 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:22.376175+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:22.376530+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:54:22.376894+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:54:22.377819+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.2.mlp.down_proj using 512 samples\n",
      "2025-06-17T06:54:25.042457+0000 | compress | METRIC - time 2.66s\n",
      "2025-06-17T06:54:25.043846+0000 | compress | METRIC - error 156.43\n",
      "2025-06-17T06:54:25.044608+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:54:25.044961+0000 | compress | METRIC - GPU 1 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:25.045344+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:25.045739+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:54:25.046104+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(3/23): Propagating: 100%|██████████| 512/512 [00:02<00:00, 186.32it/s]\n",
      "(4/23): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 69.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:54:35.207682+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.3.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:54:36.206409+0000 | compress | METRIC - time 1.00s\n",
      "2025-06-17T06:54:36.207452+0000 | compress | METRIC - error 1755.28\n",
      "2025-06-17T06:54:36.208233+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:54:36.208626+0000 | compress | METRIC - GPU 1 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:36.209007+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:36.209417+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:54:36.209830+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:54:36.210867+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.3.self_attn.k_proj using 512 samples\n",
      "2025-06-17T06:54:37.188087+0000 | compress | METRIC - time 0.98s\n",
      "2025-06-17T06:54:37.189143+0000 | compress | METRIC - error 719.07\n",
      "2025-06-17T06:54:37.189940+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:54:37.190328+0000 | compress | METRIC - GPU 1 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:37.190729+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:37.191111+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:54:37.191498+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:54:37.192539+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.3.self_attn.v_proj using 512 samples\n",
      "2025-06-17T06:54:38.178051+0000 | compress | METRIC - time 0.99s\n",
      "2025-06-17T06:54:38.179057+0000 | compress | METRIC - error 33.19\n",
      "2025-06-17T06:54:38.179874+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:54:38.180230+0000 | compress | METRIC - GPU 1 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:38.180609+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:38.180993+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:54:38.181408+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:54:38.182518+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.3.self_attn.o_proj using 512 samples\n",
      "2025-06-17T06:54:39.171758+0000 | compress | METRIC - time 0.99s\n",
      "2025-06-17T06:54:39.172859+0000 | compress | METRIC - error 0.99\n",
      "2025-06-17T06:54:39.173660+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:54:39.174014+0000 | compress | METRIC - GPU 1 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:39.174416+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:39.174797+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:54:39.175194+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:54:39.176201+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.3.mlp.gate_proj using 512 samples\n",
      "2025-06-17T06:54:40.180658+0000 | compress | METRIC - time 1.00s\n",
      "2025-06-17T06:54:40.181548+0000 | compress | METRIC - error 779.58\n",
      "2025-06-17T06:54:40.182301+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:54:40.182701+0000 | compress | METRIC - GPU 1 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:40.183055+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:40.183431+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:54:40.183806+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:54:40.184865+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.3.mlp.up_proj using 512 samples\n",
      "2025-06-17T06:54:41.187786+0000 | compress | METRIC - time 1.00s\n",
      "2025-06-17T06:54:41.188790+0000 | compress | METRIC - error 677.93\n",
      "2025-06-17T06:54:41.189585+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:54:41.189976+0000 | compress | METRIC - GPU 1 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:41.190350+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:41.190745+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:54:41.191123+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:54:41.192155+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.3.mlp.down_proj using 512 samples\n",
      "2025-06-17T06:54:43.899820+0000 | compress | METRIC - time 2.71s\n",
      "2025-06-17T06:54:43.900857+0000 | compress | METRIC - error 4.09\n",
      "2025-06-17T06:54:43.901663+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:54:43.902023+0000 | compress | METRIC - GPU 1 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:43.902450+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:43.902893+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:54:43.903273+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(4/23): Propagating: 100%|██████████| 512/512 [00:02<00:00, 186.53it/s]\n",
      "(5/23): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 69.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:54:53.986057+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.4.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:54:55.064482+0000 | compress | METRIC - time 1.08s\n",
      "2025-06-17T06:54:55.065476+0000 | compress | METRIC - error 3198.23\n",
      "2025-06-17T06:54:55.066303+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:54:55.066675+0000 | compress | METRIC - GPU 1 | usage: 11.64% | total memory: 24 GB\n",
      "2025-06-17T06:54:55.067043+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:55.067430+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:54:55.067785+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:54:55.068820+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.4.self_attn.k_proj using 512 samples\n",
      "2025-06-17T06:54:56.079398+0000 | compress | METRIC - time 1.01s\n",
      "2025-06-17T06:54:56.080111+0000 | compress | METRIC - error 1603.61\n",
      "2025-06-17T06:54:56.080861+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:54:56.081261+0000 | compress | METRIC - GPU 1 | usage: 11.64% | total memory: 24 GB\n",
      "2025-06-17T06:54:56.081687+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:56.082112+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:54:56.082524+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:54:56.083650+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.4.self_attn.v_proj using 512 samples\n",
      "2025-06-17T06:54:57.104598+0000 | compress | METRIC - time 1.02s\n",
      "2025-06-17T06:54:57.105731+0000 | compress | METRIC - error 54.31\n",
      "2025-06-17T06:54:57.106670+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:54:57.107085+0000 | compress | METRIC - GPU 1 | usage: 11.64% | total memory: 24 GB\n",
      "2025-06-17T06:54:57.107482+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:57.107859+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:54:57.108253+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:54:57.109442+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.4.self_attn.o_proj using 512 samples\n",
      "2025-06-17T06:54:58.137393+0000 | compress | METRIC - time 1.03s\n",
      "2025-06-17T06:54:58.138277+0000 | compress | METRIC - error 1.49\n",
      "2025-06-17T06:54:58.139089+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:54:58.139496+0000 | compress | METRIC - GPU 1 | usage: 11.64% | total memory: 24 GB\n",
      "2025-06-17T06:54:58.139855+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:58.140232+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:54:58.140604+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:54:58.141631+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.4.mlp.gate_proj using 512 samples\n",
      "2025-06-17T06:54:59.185623+0000 | compress | METRIC - time 1.04s\n",
      "2025-06-17T06:54:59.186564+0000 | compress | METRIC - error 1068.85\n",
      "2025-06-17T06:54:59.187413+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:54:59.187834+0000 | compress | METRIC - GPU 1 | usage: 11.64% | total memory: 24 GB\n",
      "2025-06-17T06:54:59.188213+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:54:59.188610+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:54:59.189023+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:54:59.189997+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.4.mlp.up_proj using 512 samples\n",
      "2025-06-17T06:55:00.213224+0000 | compress | METRIC - time 1.02s\n",
      "2025-06-17T06:55:00.214108+0000 | compress | METRIC - error 901.92\n",
      "2025-06-17T06:55:00.214952+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:55:00.215353+0000 | compress | METRIC - GPU 1 | usage: 11.64% | total memory: 24 GB\n",
      "2025-06-17T06:55:00.215713+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:55:00.216055+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:55:00.216476+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:55:00.217449+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.4.mlp.down_proj using 512 samples\n",
      "2025-06-17T06:55:03.075432+0000 | compress | METRIC - time 2.86s\n",
      "2025-06-17T06:55:03.076994+0000 | compress | METRIC - error 6.07\n",
      "2025-06-17T06:55:03.077831+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:55:03.078185+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:55:03.078570+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:55:03.078950+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:55:03.079382+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(5/23): Propagating: 100%|██████████| 512/512 [00:03<00:00, 153.02it/s]\n",
      "(6/23): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 70.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:55:13.740835+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.5.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:55:14.756230+0000 | compress | METRIC - time 1.01s\n",
      "2025-06-17T06:55:14.757091+0000 | compress | METRIC - error 2363.78\n",
      "2025-06-17T06:55:14.757864+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:55:14.758232+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:55:14.758641+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:55:14.758984+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:55:14.759397+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:55:14.760349+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.5.self_attn.k_proj using 512 samples\n",
      "2025-06-17T06:55:15.741053+0000 | compress | METRIC - time 0.98s\n",
      "2025-06-17T06:55:15.741988+0000 | compress | METRIC - error 1085.41\n",
      "2025-06-17T06:55:15.742861+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:55:15.743237+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:55:15.743666+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:55:15.744039+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:55:15.744456+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:55:15.745447+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.5.self_attn.v_proj using 512 samples\n",
      "2025-06-17T06:55:16.731562+0000 | compress | METRIC - time 0.99s\n",
      "2025-06-17T06:55:16.732451+0000 | compress | METRIC - error 49.94\n",
      "2025-06-17T06:55:16.733181+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:55:16.733560+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:55:16.733926+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:55:16.734236+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:55:16.734633+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:55:16.735704+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.5.self_attn.o_proj using 512 samples\n",
      "2025-06-17T06:55:17.734974+0000 | compress | METRIC - time 1.00s\n",
      "2025-06-17T06:55:17.735931+0000 | compress | METRIC - error 1.92\n",
      "2025-06-17T06:55:17.736762+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:55:17.737132+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:55:17.737518+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:55:17.737863+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:55:17.738280+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:55:17.739267+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.5.mlp.gate_proj using 512 samples\n",
      "2025-06-17T06:55:18.771635+0000 | compress | METRIC - time 1.03s\n",
      "2025-06-17T06:55:18.772475+0000 | compress | METRIC - error 1373.59\n",
      "2025-06-17T06:55:18.773237+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:55:18.773601+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:55:18.773967+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:55:18.774347+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:55:18.774761+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:55:18.775742+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.5.mlp.up_proj using 512 samples\n",
      "2025-06-17T06:55:19.813676+0000 | compress | METRIC - time 1.04s\n",
      "2025-06-17T06:55:19.814582+0000 | compress | METRIC - error 1130.38\n",
      "2025-06-17T06:55:19.815356+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:55:19.815730+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:55:19.816079+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:55:19.816431+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:55:19.816779+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:55:19.817753+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.5.mlp.down_proj using 512 samples\n",
      "2025-06-17T06:55:22.626692+0000 | compress | METRIC - time 2.81s\n",
      "2025-06-17T06:55:22.628059+0000 | compress | METRIC - error 9.42\n",
      "2025-06-17T06:55:22.628808+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:55:22.629167+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:55:22.629554+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:55:22.629920+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:55:22.630266+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(6/23): Propagating: 100%|██████████| 512/512 [00:02<00:00, 173.40it/s]\n",
      "(7/23): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 70.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:55:32.891920+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.6.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:55:33.919240+0000 | compress | METRIC - time 1.03s\n",
      "2025-06-17T06:55:33.920232+0000 | compress | METRIC - error 2844.27\n",
      "2025-06-17T06:55:33.921098+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:55:33.921487+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:55:33.921884+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:55:33.922261+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:55:33.922663+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:55:33.923716+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.6.self_attn.k_proj using 512 samples\n",
      "2025-06-17T06:55:34.917712+0000 | compress | METRIC - time 0.99s\n",
      "2025-06-17T06:55:34.918578+0000 | compress | METRIC - error 1213.37\n",
      "2025-06-17T06:55:34.919303+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:55:34.919695+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:55:34.920034+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:55:34.920419+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:55:34.920819+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:55:34.921778+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.6.self_attn.v_proj using 512 samples\n",
      "2025-06-17T06:55:35.926574+0000 | compress | METRIC - time 1.00s\n",
      "2025-06-17T06:55:35.927542+0000 | compress | METRIC - error 59.43\n",
      "2025-06-17T06:55:35.928354+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:55:35.928815+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:55:35.929188+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:55:35.929575+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:55:35.929985+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:55:35.931032+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.6.self_attn.o_proj using 512 samples\n",
      "2025-06-17T06:55:36.941580+0000 | compress | METRIC - time 1.01s\n",
      "2025-06-17T06:55:36.942635+0000 | compress | METRIC - error 3.19\n",
      "2025-06-17T06:55:36.943749+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:55:36.944286+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:55:36.944765+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:55:36.945117+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:55:36.945576+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:55:36.946759+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.6.mlp.gate_proj using 512 samples\n",
      "2025-06-17T06:55:37.968823+0000 | compress | METRIC - time 1.02s\n",
      "2025-06-17T06:55:37.969744+0000 | compress | METRIC - error 1645.81\n",
      "2025-06-17T06:55:37.970535+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:55:37.970880+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:55:37.971243+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:55:37.971591+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:55:37.971960+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:55:37.972917+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.6.mlp.up_proj using 512 samples\n",
      "2025-06-17T06:55:38.999851+0000 | compress | METRIC - time 1.03s\n",
      "2025-06-17T06:55:39.000805+0000 | compress | METRIC - error 1279.87\n",
      "2025-06-17T06:55:39.001586+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:55:39.001933+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:55:39.002292+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:55:39.002694+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:55:39.003103+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:55:39.004071+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.6.mlp.down_proj using 512 samples\n",
      "2025-06-17T06:55:41.800385+0000 | compress | METRIC - time 2.80s\n",
      "2025-06-17T06:55:41.801796+0000 | compress | METRIC - error 13.64\n",
      "2025-06-17T06:55:41.859593+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:55:41.859985+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:55:41.860336+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:55:41.860723+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:55:41.861096+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(7/23): Propagating: 100%|██████████| 512/512 [00:02<00:00, 172.78it/s]\n",
      "(8/23): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 70.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:55:52.142098+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.7.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:55:53.173111+0000 | compress | METRIC - time 1.03s\n",
      "2025-06-17T06:55:53.173953+0000 | compress | METRIC - error 3403.51\n",
      "2025-06-17T06:55:53.174902+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:55:53.175255+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:55:53.175694+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:55:53.176072+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:55:53.176474+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:55:53.177568+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.7.self_attn.k_proj using 512 samples\n",
      "2025-06-17T06:55:54.200499+0000 | compress | METRIC - time 1.02s\n",
      "2025-06-17T06:55:54.201585+0000 | compress | METRIC - error 1184.01\n",
      "2025-06-17T06:55:54.202484+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:55:54.202869+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:55:54.203220+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:55:54.203642+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:55:54.204090+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:55:54.205160+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.7.self_attn.v_proj using 512 samples\n",
      "2025-06-17T06:55:55.192057+0000 | compress | METRIC - time 0.99s\n",
      "2025-06-17T06:55:55.193109+0000 | compress | METRIC - error 88.47\n",
      "2025-06-17T06:55:55.194080+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:55:55.194494+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:55:55.194870+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:55:55.195224+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:55:55.195686+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:55:55.196772+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.7.self_attn.o_proj using 512 samples\n",
      "2025-06-17T06:55:56.187276+0000 | compress | METRIC - time 0.99s\n",
      "2025-06-17T06:55:56.188197+0000 | compress | METRIC - error 5.88\n",
      "2025-06-17T06:55:56.189002+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:55:56.189399+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:55:56.189827+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:55:56.190199+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:55:56.190687+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:55:56.191743+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.7.mlp.gate_proj using 512 samples\n",
      "2025-06-17T06:55:57.200570+0000 | compress | METRIC - time 1.01s\n",
      "2025-06-17T06:55:57.201558+0000 | compress | METRIC - error 2250.92\n",
      "2025-06-17T06:55:57.202457+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:55:57.202809+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:55:57.203193+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:55:57.203626+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:55:57.204003+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:55:57.205106+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.7.mlp.up_proj using 512 samples\n",
      "2025-06-17T06:55:58.229344+0000 | compress | METRIC - time 1.02s\n",
      "2025-06-17T06:55:58.230191+0000 | compress | METRIC - error 1479.46\n",
      "2025-06-17T06:55:58.231037+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:55:58.231422+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:55:58.231836+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:55:58.232219+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:55:58.232618+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:55:58.233714+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.7.mlp.down_proj using 512 samples\n",
      "2025-06-17T06:56:00.993898+0000 | compress | METRIC - time 2.76s\n",
      "2025-06-17T06:56:00.995267+0000 | compress | METRIC - error 238.36\n",
      "2025-06-17T06:56:00.996297+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:56:00.996767+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:56:00.997211+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:56:00.997742+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:56:00.998320+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(8/23): Propagating: 100%|██████████| 512/512 [00:02<00:00, 172.53it/s]\n",
      "(9/23): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 70.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:56:11.282649+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.8.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:56:12.276456+0000 | compress | METRIC - time 0.99s\n",
      "2025-06-17T06:56:12.277149+0000 | compress | METRIC - error 5764.24\n",
      "2025-06-17T06:56:12.277995+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:56:12.278337+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:56:12.278732+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:56:12.279095+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:56:12.279507+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:56:12.280592+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.8.self_attn.k_proj using 512 samples\n",
      "2025-06-17T06:56:13.301206+0000 | compress | METRIC - time 1.02s\n",
      "2025-06-17T06:56:13.302082+0000 | compress | METRIC - error 2473.94\n",
      "2025-06-17T06:56:13.302975+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:56:13.303309+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:56:13.303754+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:56:13.304129+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:56:13.304534+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:56:13.305632+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.8.self_attn.v_proj using 512 samples\n",
      "2025-06-17T06:56:14.281150+0000 | compress | METRIC - time 0.98s\n",
      "2025-06-17T06:56:14.281890+0000 | compress | METRIC - error 125.52\n",
      "2025-06-17T06:56:14.282730+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:56:14.283059+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:56:14.283454+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:56:14.283830+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:56:14.284215+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:56:14.285299+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.8.self_attn.o_proj using 512 samples\n",
      "2025-06-17T06:56:15.278676+0000 | compress | METRIC - time 0.99s\n",
      "2025-06-17T06:56:15.279606+0000 | compress | METRIC - error 6.47\n",
      "2025-06-17T06:56:15.280491+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:56:15.280879+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:56:15.281279+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:56:15.281711+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:56:15.282115+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:56:15.283213+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.8.mlp.gate_proj using 512 samples\n",
      "2025-06-17T06:56:16.306310+0000 | compress | METRIC - time 1.02s\n",
      "2025-06-17T06:56:16.307248+0000 | compress | METRIC - error 2380.04\n",
      "2025-06-17T06:56:16.308094+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:56:16.308711+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:56:16.309074+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:56:16.309506+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:56:16.309909+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:56:16.310927+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.8.mlp.up_proj using 512 samples\n",
      "2025-06-17T06:56:17.333039+0000 | compress | METRIC - time 1.02s\n",
      "2025-06-17T06:56:17.333962+0000 | compress | METRIC - error 1735.01\n",
      "2025-06-17T06:56:17.334843+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:56:17.335237+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:56:17.335683+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:56:17.336403+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:56:17.336767+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:56:17.337566+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.8.mlp.down_proj using 512 samples\n",
      "2025-06-17T06:56:20.103152+0000 | compress | METRIC - time 2.77s\n",
      "2025-06-17T06:56:20.104548+0000 | compress | METRIC - error 24.10\n",
      "2025-06-17T06:56:20.105356+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:56:20.105733+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:56:20.106473+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:56:20.106822+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:56:20.107230+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(9/23): Propagating: 100%|██████████| 512/512 [00:02<00:00, 173.56it/s]\n",
      "(10/23): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 70.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:56:30.372193+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.9.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:56:31.398917+0000 | compress | METRIC - time 1.03s\n",
      "2025-06-17T06:56:31.399822+0000 | compress | METRIC - error 3168.07\n",
      "2025-06-17T06:56:31.400719+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:56:31.401090+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:56:31.401513+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:56:31.401927+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:56:31.402333+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:56:31.403445+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.9.self_attn.k_proj using 512 samples\n",
      "2025-06-17T06:56:32.424177+0000 | compress | METRIC - time 1.02s\n",
      "2025-06-17T06:56:32.425235+0000 | compress | METRIC - error 1293.86\n",
      "2025-06-17T06:56:32.712754+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:56:32.713358+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:56:32.713823+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:56:32.714265+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:56:32.714783+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:56:32.715969+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.9.self_attn.v_proj using 512 samples\n",
      "2025-06-17T06:56:33.707804+0000 | compress | METRIC - time 0.99s\n",
      "2025-06-17T06:56:33.708849+0000 | compress | METRIC - error 77.65\n",
      "2025-06-17T06:56:33.709629+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:56:33.709994+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:56:33.710400+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:56:33.710780+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:56:33.711174+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:56:33.712289+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.9.self_attn.o_proj using 512 samples\n",
      "2025-06-17T06:56:34.709520+0000 | compress | METRIC - time 1.00s\n",
      "2025-06-17T06:56:34.710469+0000 | compress | METRIC - error 11.41\n",
      "2025-06-17T06:56:34.711232+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:56:34.711621+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:56:34.711990+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:56:34.712352+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:56:34.712753+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:56:34.713765+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.9.mlp.gate_proj using 512 samples\n",
      "2025-06-17T06:56:35.730633+0000 | compress | METRIC - time 1.02s\n",
      "2025-06-17T06:56:35.731532+0000 | compress | METRIC - error 2762.14\n",
      "2025-06-17T06:56:35.732429+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:56:35.732785+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:56:35.733175+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:56:35.733565+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:56:35.733962+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:56:35.735041+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.9.mlp.up_proj using 512 samples\n",
      "2025-06-17T06:56:36.749986+0000 | compress | METRIC - time 1.01s\n",
      "2025-06-17T06:56:36.750989+0000 | compress | METRIC - error 1890.78\n",
      "2025-06-17T06:56:36.751747+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:56:36.752098+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:56:36.752482+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:56:36.752837+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:56:36.753224+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:56:36.754269+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.9.mlp.down_proj using 512 samples\n",
      "2025-06-17T06:56:39.522240+0000 | compress | METRIC - time 2.77s\n",
      "2025-06-17T06:56:39.523712+0000 | compress | METRIC - error 33.01\n",
      "2025-06-17T06:56:39.524608+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:56:39.524968+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:56:39.525347+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:56:39.525716+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:56:39.526101+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(10/23): Propagating: 100%|██████████| 512/512 [00:02<00:00, 173.27it/s]\n",
      "(11/23): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 70.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:56:49.794247+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.10.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:56:50.817929+0000 | compress | METRIC - time 1.02s\n",
      "2025-06-17T06:56:50.818755+0000 | compress | METRIC - error 3467.86\n",
      "2025-06-17T06:56:50.819589+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:56:50.819939+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:56:50.820309+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:56:50.820681+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:56:50.821055+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:56:50.822075+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.10.self_attn.k_proj using 512 samples\n",
      "2025-06-17T06:56:51.812620+0000 | compress | METRIC - time 0.99s\n",
      "2025-06-17T06:56:51.813594+0000 | compress | METRIC - error 1482.10\n",
      "2025-06-17T06:56:51.814392+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:56:51.814746+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:56:51.815108+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:56:51.815467+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:56:51.815820+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:56:51.816811+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.10.self_attn.v_proj using 512 samples\n",
      "2025-06-17T06:56:52.800430+0000 | compress | METRIC - time 0.98s\n",
      "2025-06-17T06:56:52.801420+0000 | compress | METRIC - error 86.19\n",
      "2025-06-17T06:56:52.802148+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:56:52.802526+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:56:52.802889+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:56:52.803211+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:56:52.803616+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:56:52.804576+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.10.self_attn.o_proj using 512 samples\n",
      "2025-06-17T06:56:53.835238+0000 | compress | METRIC - time 1.03s\n",
      "2025-06-17T06:56:53.836253+0000 | compress | METRIC - error 12.43\n",
      "2025-06-17T06:56:53.837046+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:56:53.837407+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:56:53.837775+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:56:53.838128+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:56:53.838531+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:56:53.839538+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.10.mlp.gate_proj using 512 samples\n",
      "2025-06-17T06:56:54.863624+0000 | compress | METRIC - time 1.02s\n",
      "2025-06-17T06:56:54.864527+0000 | compress | METRIC - error 2843.16\n",
      "2025-06-17T06:56:54.865290+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:56:54.865678+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:56:54.866012+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:56:54.866415+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:56:54.866818+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:56:54.867840+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.10.mlp.up_proj using 512 samples\n",
      "2025-06-17T06:56:55.873974+0000 | compress | METRIC - time 1.01s\n",
      "2025-06-17T06:56:55.874972+0000 | compress | METRIC - error 2061.60\n",
      "2025-06-17T06:56:55.875761+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:56:55.876115+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:56:55.876488+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:56:55.876861+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:56:55.877227+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:56:55.878246+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.10.mlp.down_proj using 512 samples\n",
      "2025-06-17T06:56:58.654981+0000 | compress | METRIC - time 2.78s\n",
      "2025-06-17T06:56:58.656393+0000 | compress | METRIC - error 38.58\n",
      "2025-06-17T06:56:58.657195+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:56:58.657601+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:56:58.657982+0000 | compress | METRIC - GPU 2 | usage: 8.54% | total memory: 24 GB\n",
      "2025-06-17T06:56:58.658379+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:56:58.658759+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(11/23): Propagating: 100%|██████████| 512/512 [00:02<00:00, 172.75it/s]\n",
      "(12/23): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 69.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:57:09.005804+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.11.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:57:10.083830+0000 | compress | METRIC - time 1.08s\n",
      "2025-06-17T06:57:10.084763+0000 | compress | METRIC - error 4878.73\n",
      "2025-06-17T06:57:10.085578+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:57:10.085938+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:10.086350+0000 | compress | METRIC - GPU 2 | usage: 11.64% | total memory: 24 GB\n",
      "2025-06-17T06:57:10.086705+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:57:10.087099+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:57:10.088143+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.11.self_attn.k_proj using 512 samples\n",
      "2025-06-17T06:57:11.122026+0000 | compress | METRIC - time 1.03s\n",
      "2025-06-17T06:57:11.122845+0000 | compress | METRIC - error 1753.81\n",
      "2025-06-17T06:57:11.123632+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:57:11.124012+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:11.124381+0000 | compress | METRIC - GPU 2 | usage: 11.64% | total memory: 24 GB\n",
      "2025-06-17T06:57:11.124726+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:57:11.125079+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:57:11.126082+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.11.self_attn.v_proj using 512 samples\n",
      "2025-06-17T06:57:12.170663+0000 | compress | METRIC - time 1.04s\n",
      "2025-06-17T06:57:12.171590+0000 | compress | METRIC - error 113.96\n",
      "2025-06-17T06:57:12.172389+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:57:12.172742+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:12.173116+0000 | compress | METRIC - GPU 2 | usage: 11.64% | total memory: 24 GB\n",
      "2025-06-17T06:57:12.173520+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:57:12.173917+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:57:12.174909+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.11.self_attn.o_proj using 512 samples\n",
      "2025-06-17T06:57:13.188871+0000 | compress | METRIC - time 1.01s\n",
      "2025-06-17T06:57:13.189775+0000 | compress | METRIC - error 22.58\n",
      "2025-06-17T06:57:13.190758+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:57:13.191278+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:13.191761+0000 | compress | METRIC - GPU 2 | usage: 11.64% | total memory: 24 GB\n",
      "2025-06-17T06:57:13.192248+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:57:13.192796+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:57:13.194190+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.11.mlp.gate_proj using 512 samples\n",
      "2025-06-17T06:57:14.227396+0000 | compress | METRIC - time 1.03s\n",
      "2025-06-17T06:57:14.228393+0000 | compress | METRIC - error 3301.49\n",
      "2025-06-17T06:57:14.229479+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:57:14.229979+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:14.230476+0000 | compress | METRIC - GPU 2 | usage: 11.64% | total memory: 24 GB\n",
      "2025-06-17T06:57:14.231023+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:57:14.231616+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:57:14.233036+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.11.mlp.up_proj using 512 samples\n",
      "2025-06-17T06:57:15.291460+0000 | compress | METRIC - time 1.06s\n",
      "2025-06-17T06:57:15.292403+0000 | compress | METRIC - error 2348.92\n",
      "2025-06-17T06:57:15.293468+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:57:15.293991+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:15.294546+0000 | compress | METRIC - GPU 2 | usage: 11.64% | total memory: 24 GB\n",
      "2025-06-17T06:57:15.295016+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:57:15.295577+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:57:15.297027+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.11.mlp.down_proj using 512 samples\n",
      "2025-06-17T06:57:18.118705+0000 | compress | METRIC - time 2.82s\n",
      "2025-06-17T06:57:18.120086+0000 | compress | METRIC - error 48.50\n",
      "2025-06-17T06:57:18.120916+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:57:18.121292+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:18.121686+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:18.122018+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:57:18.122469+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(12/23): Propagating: 100%|██████████| 512/512 [00:03<00:00, 153.83it/s]\n",
      "(13/23): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 69.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:57:28.777241+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.12.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:57:29.776448+0000 | compress | METRIC - time 1.00s\n",
      "2025-06-17T06:57:29.777253+0000 | compress | METRIC - error 3679.62\n",
      "2025-06-17T06:57:29.778084+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:57:29.778485+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:29.778900+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:29.779279+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:57:29.779672+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:57:29.780752+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.12.self_attn.k_proj using 512 samples\n",
      "2025-06-17T06:57:30.760323+0000 | compress | METRIC - time 0.98s\n",
      "2025-06-17T06:57:30.761238+0000 | compress | METRIC - error 1545.25\n",
      "2025-06-17T06:57:30.762073+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:57:30.762455+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:30.762857+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:30.763217+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:57:30.763693+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:57:30.764717+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.12.self_attn.v_proj using 512 samples\n",
      "2025-06-17T06:57:31.746516+0000 | compress | METRIC - time 0.98s\n",
      "2025-06-17T06:57:31.747450+0000 | compress | METRIC - error 135.00\n",
      "2025-06-17T06:57:31.748242+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:57:31.748626+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:31.749024+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:31.749439+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:57:31.749821+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:57:31.750903+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.12.self_attn.o_proj using 512 samples\n",
      "2025-06-17T06:57:32.759098+0000 | compress | METRIC - time 1.01s\n",
      "2025-06-17T06:57:32.759955+0000 | compress | METRIC - error 27.75\n",
      "2025-06-17T06:57:32.760783+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:57:32.761154+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:32.761565+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:32.761936+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:57:32.762376+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:57:32.763423+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.12.mlp.gate_proj using 512 samples\n",
      "2025-06-17T06:57:33.766881+0000 | compress | METRIC - time 1.00s\n",
      "2025-06-17T06:57:33.767879+0000 | compress | METRIC - error 4061.02\n",
      "2025-06-17T06:57:33.768744+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:57:33.769114+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:33.769541+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:33.769920+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:57:33.770293+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:57:33.771334+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.12.mlp.up_proj using 512 samples\n",
      "2025-06-17T06:57:34.773839+0000 | compress | METRIC - time 1.00s\n",
      "2025-06-17T06:57:34.774699+0000 | compress | METRIC - error 2643.43\n",
      "2025-06-17T06:57:34.775558+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:57:34.775940+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:34.776278+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:34.776675+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:57:34.777109+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:57:34.778143+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.12.mlp.down_proj using 512 samples\n",
      "2025-06-17T06:57:37.567542+0000 | compress | METRIC - time 2.79s\n",
      "2025-06-17T06:57:37.568898+0000 | compress | METRIC - error 64.82\n",
      "2025-06-17T06:57:37.569769+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:57:37.570145+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:37.570584+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:37.570991+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:57:37.571420+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(13/23): Propagating: 100%|██████████| 512/512 [00:02<00:00, 173.12it/s]\n",
      "(14/23): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 69.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:57:47.855152+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.13.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:57:48.899590+0000 | compress | METRIC - time 1.04s\n",
      "2025-06-17T06:57:48.900792+0000 | compress | METRIC - error 4123.42\n",
      "2025-06-17T06:57:48.901693+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:57:48.902053+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:48.902463+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:48.902832+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:57:48.903218+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:57:48.904196+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.13.self_attn.k_proj using 512 samples\n",
      "2025-06-17T06:57:49.930100+0000 | compress | METRIC - time 1.03s\n",
      "2025-06-17T06:57:49.930962+0000 | compress | METRIC - error 1765.75\n",
      "2025-06-17T06:57:49.931756+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:57:49.932108+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:49.932502+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:49.932831+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:57:49.933462+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:57:49.934486+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.13.self_attn.v_proj using 512 samples\n",
      "2025-06-17T06:57:50.972049+0000 | compress | METRIC - time 1.04s\n",
      "2025-06-17T06:57:50.972958+0000 | compress | METRIC - error 113.80\n",
      "2025-06-17T06:57:50.973838+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:57:50.974235+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:50.974621+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:50.974983+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:57:50.975404+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:57:50.976424+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.13.self_attn.o_proj using 512 samples\n",
      "2025-06-17T06:57:52.002113+0000 | compress | METRIC - time 1.03s\n",
      "2025-06-17T06:57:52.002994+0000 | compress | METRIC - error 35.41\n",
      "2025-06-17T06:57:52.003742+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:57:52.004086+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:52.004496+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:52.004882+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:57:52.005255+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:57:52.006343+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.13.mlp.gate_proj using 512 samples\n",
      "2025-06-17T06:57:53.054699+0000 | compress | METRIC - time 1.05s\n",
      "2025-06-17T06:57:53.055712+0000 | compress | METRIC - error 4417.37\n",
      "2025-06-17T06:57:53.056531+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:57:53.056883+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:53.057249+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:53.057618+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:57:53.057984+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:57:53.058984+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.13.mlp.up_proj using 512 samples\n",
      "2025-06-17T06:57:54.078647+0000 | compress | METRIC - time 1.02s\n",
      "2025-06-17T06:57:54.079562+0000 | compress | METRIC - error 2950.49\n",
      "2025-06-17T06:57:54.080317+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:57:54.080716+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:54.081101+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:54.081489+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:57:54.081872+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:57:54.082938+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.13.mlp.down_proj using 512 samples\n",
      "2025-06-17T06:57:56.852096+0000 | compress | METRIC - time 2.77s\n",
      "2025-06-17T06:57:56.853505+0000 | compress | METRIC - error 85.29\n",
      "2025-06-17T06:57:56.854245+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:57:56.854681+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:56.855036+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:57:56.855383+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:57:56.855775+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(14/23): Propagating: 100%|██████████| 512/512 [00:02<00:00, 173.26it/s]\n",
      "(15/23): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 69.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:58:07.141210+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.14.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:58:08.206459+0000 | compress | METRIC - time 1.06s\n",
      "2025-06-17T06:58:08.207604+0000 | compress | METRIC - error 3887.89\n",
      "2025-06-17T06:58:08.208806+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:58:08.209294+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:08.209843+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:08.210453+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:58:08.211006+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:58:08.212651+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.14.self_attn.k_proj using 512 samples\n",
      "2025-06-17T06:58:09.213945+0000 | compress | METRIC - time 1.00s\n",
      "2025-06-17T06:58:09.214922+0000 | compress | METRIC - error 1726.07\n",
      "2025-06-17T06:58:09.215817+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:58:09.216191+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:09.216637+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:09.217009+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:58:09.217427+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:58:09.218541+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.14.self_attn.v_proj using 512 samples\n",
      "2025-06-17T06:58:10.224534+0000 | compress | METRIC - time 1.01s\n",
      "2025-06-17T06:58:10.225554+0000 | compress | METRIC - error 129.98\n",
      "2025-06-17T06:58:10.226327+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:58:10.226712+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:10.227085+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:10.227472+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:58:10.227853+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:58:10.228905+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.14.self_attn.o_proj using 512 samples\n",
      "2025-06-17T06:58:11.223152+0000 | compress | METRIC - time 0.99s\n",
      "2025-06-17T06:58:11.224101+0000 | compress | METRIC - error 58.25\n",
      "2025-06-17T06:58:11.224899+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:58:11.225247+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:11.225639+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:11.226002+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:58:11.226407+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:58:11.227411+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.14.mlp.gate_proj using 512 samples\n",
      "2025-06-17T06:58:12.248000+0000 | compress | METRIC - time 1.02s\n",
      "2025-06-17T06:58:12.248917+0000 | compress | METRIC - error 4768.79\n",
      "2025-06-17T06:58:12.249771+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:58:12.250139+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:12.250546+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:12.250882+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:58:12.251259+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:58:12.252324+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.14.mlp.up_proj using 512 samples\n",
      "2025-06-17T06:58:13.259410+0000 | compress | METRIC - time 1.01s\n",
      "2025-06-17T06:58:13.260288+0000 | compress | METRIC - error 3344.34\n",
      "2025-06-17T06:58:13.261107+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:58:13.261497+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:13.261872+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:13.262244+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:58:13.262642+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:58:13.263666+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.14.mlp.down_proj using 512 samples\n",
      "2025-06-17T06:58:16.028026+0000 | compress | METRIC - time 2.76s\n",
      "2025-06-17T06:58:16.029376+0000 | compress | METRIC - error 109.46\n",
      "2025-06-17T06:58:16.030191+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:58:16.030598+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:16.030969+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:16.031306+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:58:16.032139+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(15/23): Propagating: 100%|██████████| 512/512 [00:02<00:00, 173.01it/s]\n",
      "(16/23): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 69.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:58:26.324861+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.15.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:58:27.357492+0000 | compress | METRIC - time 1.03s\n",
      "2025-06-17T06:58:27.358444+0000 | compress | METRIC - error 5661.25\n",
      "2025-06-17T06:58:27.359191+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:58:27.359660+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:27.360011+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:27.360447+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:58:27.360906+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:58:27.361956+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.15.self_attn.k_proj using 512 samples\n",
      "2025-06-17T06:58:28.338677+0000 | compress | METRIC - time 0.98s\n",
      "2025-06-17T06:58:28.339622+0000 | compress | METRIC - error 1905.40\n",
      "2025-06-17T06:58:28.340421+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:58:28.340762+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:28.341131+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:28.341507+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:58:28.341909+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:58:28.342960+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.15.self_attn.v_proj using 512 samples\n",
      "2025-06-17T06:58:29.320632+0000 | compress | METRIC - time 0.98s\n",
      "2025-06-17T06:58:29.321566+0000 | compress | METRIC - error 224.03\n",
      "2025-06-17T06:58:29.322301+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:58:29.322667+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:29.323036+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:29.323412+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:58:29.323795+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:58:29.324884+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.15.self_attn.o_proj using 512 samples\n",
      "2025-06-17T06:58:30.348228+0000 | compress | METRIC - time 1.02s\n",
      "2025-06-17T06:58:30.348979+0000 | compress | METRIC - error 49.87\n",
      "2025-06-17T06:58:30.349828+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:58:30.350204+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:30.350613+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:30.350946+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:58:30.351351+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:58:30.352350+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.15.mlp.gate_proj using 512 samples\n",
      "2025-06-17T06:58:31.377968+0000 | compress | METRIC - time 1.03s\n",
      "2025-06-17T06:58:31.378809+0000 | compress | METRIC - error 5337.38\n",
      "2025-06-17T06:58:31.379584+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:58:31.379961+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:31.380288+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:31.380672+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:58:31.381058+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:58:31.382027+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.15.mlp.up_proj using 512 samples\n",
      "2025-06-17T06:58:32.425970+0000 | compress | METRIC - time 1.04s\n",
      "2025-06-17T06:58:32.426805+0000 | compress | METRIC - error 3849.43\n",
      "2025-06-17T06:58:32.427636+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:58:32.427982+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:32.428348+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:32.428716+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:58:32.429090+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:58:32.430132+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.15.mlp.down_proj using 512 samples\n",
      "2025-06-17T06:58:35.277012+0000 | compress | METRIC - time 2.85s\n",
      "2025-06-17T06:58:35.278340+0000 | compress | METRIC - error 172.97\n",
      "2025-06-17T06:58:35.279156+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:58:35.279569+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:35.279957+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:35.280380+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:58:35.280807+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(16/23): Propagating: 100%|██████████| 512/512 [00:02<00:00, 173.51it/s]\n",
      "(17/23): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 69.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:58:45.560971+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.16.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:58:46.570000+0000 | compress | METRIC - time 1.01s\n",
      "2025-06-17T06:58:46.570951+0000 | compress | METRIC - error 5774.99\n",
      "2025-06-17T06:58:46.571904+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:58:46.572316+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:46.572890+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:46.573428+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:58:46.573848+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:58:46.574932+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.16.self_attn.k_proj using 512 samples\n",
      "2025-06-17T06:58:47.583294+0000 | compress | METRIC - time 1.01s\n",
      "2025-06-17T06:58:47.584253+0000 | compress | METRIC - error 1960.76\n",
      "2025-06-17T06:58:47.585081+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:58:47.585526+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:47.585921+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:47.586436+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:58:47.586872+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:58:47.588052+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.16.self_attn.v_proj using 512 samples\n",
      "2025-06-17T06:58:48.603160+0000 | compress | METRIC - time 1.01s\n",
      "2025-06-17T06:58:48.604133+0000 | compress | METRIC - error 209.80\n",
      "2025-06-17T06:58:48.604962+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:58:48.605317+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:48.605707+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:48.606062+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:58:48.606447+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:58:48.607431+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.16.self_attn.o_proj using 512 samples\n",
      "2025-06-17T06:58:49.628820+0000 | compress | METRIC - time 1.02s\n",
      "2025-06-17T06:58:49.629722+0000 | compress | METRIC - error 58.50\n",
      "2025-06-17T06:58:49.630467+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:58:49.630812+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:49.631175+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:49.631545+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:58:49.631937+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:58:49.632880+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.16.mlp.gate_proj using 512 samples\n",
      "2025-06-17T06:58:50.690716+0000 | compress | METRIC - time 1.06s\n",
      "2025-06-17T06:58:50.691623+0000 | compress | METRIC - error 6843.13\n",
      "2025-06-17T06:58:50.692432+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:58:50.692773+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:50.693139+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:50.693502+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:58:50.693862+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:58:50.694865+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.16.mlp.up_proj using 512 samples\n",
      "2025-06-17T06:58:51.739671+0000 | compress | METRIC - time 1.04s\n",
      "2025-06-17T06:58:51.740571+0000 | compress | METRIC - error 4661.19\n",
      "2025-06-17T06:58:51.741350+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:58:51.741728+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:51.742100+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:51.742494+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:58:51.742880+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:58:51.743890+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.16.mlp.down_proj using 512 samples\n",
      "2025-06-17T06:58:54.601961+0000 | compress | METRIC - time 2.86s\n",
      "2025-06-17T06:58:54.603389+0000 | compress | METRIC - error 274.70\n",
      "2025-06-17T06:58:54.604154+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:58:54.604514+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:54.604883+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:58:54.605223+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:58:54.605586+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(17/23): Propagating: 100%|██████████| 512/512 [00:02<00:00, 173.32it/s]\n",
      "(18/23): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 69.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:59:04.894188+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.17.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:59:05.918918+0000 | compress | METRIC - time 1.02s\n",
      "2025-06-17T06:59:05.919929+0000 | compress | METRIC - error 5366.07\n",
      "2025-06-17T06:59:05.920737+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:59:05.921100+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:05.921497+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:05.921870+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:59:05.922284+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:59:05.923277+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.17.self_attn.k_proj using 512 samples\n",
      "2025-06-17T06:59:06.912793+0000 | compress | METRIC - time 0.99s\n",
      "2025-06-17T06:59:06.913887+0000 | compress | METRIC - error 2040.75\n",
      "2025-06-17T06:59:06.914695+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:59:06.915078+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:06.915477+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:06.915846+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:59:06.916206+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:59:06.917237+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.17.self_attn.v_proj using 512 samples\n",
      "2025-06-17T06:59:07.908172+0000 | compress | METRIC - time 0.99s\n",
      "2025-06-17T06:59:07.909113+0000 | compress | METRIC - error 394.28\n",
      "2025-06-17T06:59:07.909888+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:59:07.910392+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:07.910787+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:07.911153+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:59:07.911550+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:59:07.912586+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.17.self_attn.o_proj using 512 samples\n",
      "2025-06-17T06:59:08.926058+0000 | compress | METRIC - time 1.01s\n",
      "2025-06-17T06:59:08.926995+0000 | compress | METRIC - error 82.40\n",
      "2025-06-17T06:59:08.927791+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:59:08.928190+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:08.928605+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:08.928934+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:59:08.929384+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:59:08.930422+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.17.mlp.gate_proj using 512 samples\n",
      "2025-06-17T06:59:09.966950+0000 | compress | METRIC - time 1.04s\n",
      "2025-06-17T06:59:09.967889+0000 | compress | METRIC - error 7853.72\n",
      "2025-06-17T06:59:09.968732+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:59:09.969079+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:09.969531+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:09.970215+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:59:09.970611+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:59:09.971310+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.17.mlp.up_proj using 512 samples\n",
      "2025-06-17T06:59:10.976770+0000 | compress | METRIC - time 1.01s\n",
      "2025-06-17T06:59:10.977753+0000 | compress | METRIC - error 5571.22\n",
      "2025-06-17T06:59:10.978582+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:59:10.978941+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:10.979349+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:10.979708+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:59:10.980068+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:59:10.981068+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.17.mlp.down_proj using 512 samples\n",
      "2025-06-17T06:59:13.754129+0000 | compress | METRIC - time 2.77s\n",
      "2025-06-17T06:59:13.755569+0000 | compress | METRIC - error 319.99\n",
      "2025-06-17T06:59:13.756395+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:59:13.756877+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:13.757278+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:13.757646+0000 | compress | METRIC - GPU 3 | usage: 7.36% | total memory: 24 GB\n",
      "2025-06-17T06:59:13.758064+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(18/23): Propagating: 100%|██████████| 512/512 [00:02<00:00, 172.59it/s]\n",
      "(19/23): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 67.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:59:24.346779+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.18.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:59:25.383796+0000 | compress | METRIC - time 1.04s\n",
      "2025-06-17T06:59:25.384655+0000 | compress | METRIC - error 6100.59\n",
      "2025-06-17T06:59:25.385410+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:59:25.385754+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:25.386143+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:25.386512+0000 | compress | METRIC - GPU 3 | usage: 10.51% | total memory: 24 GB\n",
      "2025-06-17T06:59:25.386908+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:59:25.387880+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.18.self_attn.k_proj using 512 samples\n",
      "2025-06-17T06:59:26.389163+0000 | compress | METRIC - time 1.00s\n",
      "2025-06-17T06:59:26.389973+0000 | compress | METRIC - error 2349.14\n",
      "2025-06-17T06:59:26.390756+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:59:26.391133+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:26.391496+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:26.391857+0000 | compress | METRIC - GPU 3 | usage: 10.51% | total memory: 24 GB\n",
      "2025-06-17T06:59:26.392270+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:59:26.393234+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.18.self_attn.v_proj using 512 samples\n",
      "2025-06-17T06:59:27.396831+0000 | compress | METRIC - time 1.00s\n",
      "2025-06-17T06:59:27.397632+0000 | compress | METRIC - error 630.46\n",
      "2025-06-17T06:59:27.398394+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:59:27.398735+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:27.399084+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:27.399463+0000 | compress | METRIC - GPU 3 | usage: 10.51% | total memory: 24 GB\n",
      "2025-06-17T06:59:27.399889+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:59:27.400844+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.18.self_attn.o_proj using 512 samples\n",
      "2025-06-17T06:59:28.418091+0000 | compress | METRIC - time 1.02s\n",
      "2025-06-17T06:59:28.418834+0000 | compress | METRIC - error 115.19\n",
      "2025-06-17T06:59:28.419633+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:59:28.419979+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:28.420345+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:28.420710+0000 | compress | METRIC - GPU 3 | usage: 10.51% | total memory: 24 GB\n",
      "2025-06-17T06:59:28.421095+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:59:28.422071+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.18.mlp.gate_proj using 512 samples\n",
      "2025-06-17T06:59:29.453340+0000 | compress | METRIC - time 1.03s\n",
      "2025-06-17T06:59:29.454240+0000 | compress | METRIC - error 9621.21\n",
      "2025-06-17T06:59:29.454990+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:59:29.455381+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:29.455705+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:29.456056+0000 | compress | METRIC - GPU 3 | usage: 10.51% | total memory: 24 GB\n",
      "2025-06-17T06:59:29.456453+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:59:29.457442+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.18.mlp.up_proj using 512 samples\n",
      "2025-06-17T06:59:30.475831+0000 | compress | METRIC - time 1.02s\n",
      "2025-06-17T06:59:30.476912+0000 | compress | METRIC - error 6929.69\n",
      "2025-06-17T06:59:30.477794+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:59:30.478137+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:30.478541+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:30.478861+0000 | compress | METRIC - GPU 3 | usage: 10.51% | total memory: 24 GB\n",
      "2025-06-17T06:59:30.479229+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:59:30.480199+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.18.mlp.down_proj using 512 samples\n",
      "2025-06-17T06:59:33.288289+0000 | compress | METRIC - time 2.81s\n",
      "2025-06-17T06:59:33.289669+0000 | compress | METRIC - error 520.91\n",
      "2025-06-17T06:59:33.290461+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:59:33.290855+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:33.291208+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:33.291574+0000 | compress | METRIC - GPU 3 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:59:33.291981+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(19/23): Propagating: 100%|██████████| 512/512 [00:03<00:00, 157.29it/s]\n",
      "(20/23): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 69.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:59:43.917852+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.19.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T06:59:44.914004+0000 | compress | METRIC - time 0.99s\n",
      "2025-06-17T06:59:44.914822+0000 | compress | METRIC - error 5810.61\n",
      "2025-06-17T06:59:44.915583+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:59:44.915902+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:44.916209+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:44.916547+0000 | compress | METRIC - GPU 3 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:59:44.916879+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:59:44.917851+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.19.self_attn.k_proj using 512 samples\n",
      "2025-06-17T06:59:45.888879+0000 | compress | METRIC - time 0.97s\n",
      "2025-06-17T06:59:45.889700+0000 | compress | METRIC - error 2158.59\n",
      "2025-06-17T06:59:45.890487+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:59:45.890792+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:45.891118+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:45.891467+0000 | compress | METRIC - GPU 3 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:59:45.891828+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:59:45.892781+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.19.self_attn.v_proj using 512 samples\n",
      "2025-06-17T06:59:46.873791+0000 | compress | METRIC - time 0.98s\n",
      "2025-06-17T06:59:46.874695+0000 | compress | METRIC - error 712.82\n",
      "2025-06-17T06:59:46.875424+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:59:46.875742+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:46.876058+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:46.876405+0000 | compress | METRIC - GPU 3 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:59:46.876765+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T06:59:46.877726+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.19.self_attn.o_proj using 512 samples\n",
      "2025-06-17T06:59:47.854981+0000 | compress | METRIC - time 0.98s\n",
      "2025-06-17T06:59:47.855804+0000 | compress | METRIC - error 140.80\n",
      "2025-06-17T06:59:47.856529+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:59:47.856845+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:47.857173+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:47.857515+0000 | compress | METRIC - GPU 3 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:59:47.857877+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T06:59:47.858832+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.19.mlp.gate_proj using 512 samples\n",
      "2025-06-17T06:59:48.862739+0000 | compress | METRIC - time 1.00s\n",
      "2025-06-17T06:59:48.863580+0000 | compress | METRIC - error 11414.29\n",
      "2025-06-17T06:59:48.864291+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:59:48.864661+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:48.864993+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:48.865316+0000 | compress | METRIC - GPU 3 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:59:48.865663+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:59:48.866645+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.19.mlp.up_proj using 512 samples\n",
      "2025-06-17T06:59:49.856929+0000 | compress | METRIC - time 0.99s\n",
      "2025-06-17T06:59:49.857674+0000 | compress | METRIC - error 8578.47\n",
      "2025-06-17T06:59:49.858407+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:59:49.858719+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:49.859047+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:49.859394+0000 | compress | METRIC - GPU 3 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:59:49.859737+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T06:59:49.860699+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.19.mlp.down_proj using 512 samples\n",
      "2025-06-17T06:59:52.592034+0000 | compress | METRIC - time 2.73s\n",
      "2025-06-17T06:59:52.593236+0000 | compress | METRIC - error 837.97\n",
      "2025-06-17T06:59:52.594024+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:59:52.594330+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:52.594681+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T06:59:52.594995+0000 | compress | METRIC - GPU 3 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T06:59:52.595319+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(20/23): Propagating: 100%|██████████| 512/512 [00:02<00:00, 175.34it/s]\n",
      "(21/23): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 69.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T07:00:02.875735+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.20.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T07:00:03.907839+0000 | compress | METRIC - time 1.03s\n",
      "2025-06-17T07:00:03.908811+0000 | compress | METRIC - error 5879.96\n",
      "2025-06-17T07:00:03.909586+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T07:00:03.909994+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T07:00:03.910428+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T07:00:03.910821+0000 | compress | METRIC - GPU 3 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T07:00:03.911240+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T07:00:03.912309+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.20.self_attn.k_proj using 512 samples\n",
      "2025-06-17T07:00:04.942583+0000 | compress | METRIC - time 1.03s\n",
      "2025-06-17T07:00:04.943496+0000 | compress | METRIC - error 2162.16\n",
      "2025-06-17T07:00:04.944340+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T07:00:04.944727+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T07:00:04.945131+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T07:00:04.945512+0000 | compress | METRIC - GPU 3 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T07:00:04.945931+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T07:00:04.947096+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.20.self_attn.v_proj using 512 samples\n",
      "2025-06-17T07:00:05.961672+0000 | compress | METRIC - time 1.01s\n",
      "2025-06-17T07:00:05.962610+0000 | compress | METRIC - error 554.14\n",
      "2025-06-17T07:00:05.963345+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T07:00:05.963775+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T07:00:05.964170+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T07:00:05.964618+0000 | compress | METRIC - GPU 3 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T07:00:05.964985+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T07:00:05.966090+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.20.self_attn.o_proj using 512 samples\n",
      "2025-06-17T07:00:06.988482+0000 | compress | METRIC - time 1.02s\n",
      "2025-06-17T07:00:06.989190+0000 | compress | METRIC - error 167.11\n",
      "2025-06-17T07:00:06.990022+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T07:00:06.990457+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T07:00:06.990801+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T07:00:06.991172+0000 | compress | METRIC - GPU 3 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T07:00:06.991582+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T07:00:06.992619+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.20.mlp.gate_proj using 512 samples\n",
      "2025-06-17T07:00:08.046260+0000 | compress | METRIC - time 1.05s\n",
      "2025-06-17T07:00:08.047294+0000 | compress | METRIC - error 13148.81\n",
      "2025-06-17T07:00:08.048068+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T07:00:08.048448+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T07:00:08.048831+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T07:00:08.049196+0000 | compress | METRIC - GPU 3 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T07:00:08.049602+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T07:00:08.050590+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.20.mlp.up_proj using 512 samples\n",
      "2025-06-17T07:00:09.103695+0000 | compress | METRIC - time 1.05s\n",
      "2025-06-17T07:00:09.104955+0000 | compress | METRIC - error 10143.96\n",
      "2025-06-17T07:00:09.105805+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T07:00:09.106163+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T07:00:09.106596+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T07:00:09.106946+0000 | compress | METRIC - GPU 3 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T07:00:09.107328+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T07:00:09.108347+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.20.mlp.down_proj using 512 samples\n",
      "2025-06-17T07:00:11.968969+0000 | compress | METRIC - time 2.86s\n",
      "2025-06-17T07:00:11.970423+0000 | compress | METRIC - error 1313.63\n",
      "2025-06-17T07:00:11.971232+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T07:00:11.971638+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T07:00:11.972010+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T07:00:11.972404+0000 | compress | METRIC - GPU 3 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T07:00:11.972807+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(21/23): Propagating: 100%|██████████| 512/512 [00:02<00:00, 176.10it/s]\n",
      "(22/23): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 69.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T07:00:22.246570+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.21.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T07:00:23.243706+0000 | compress | METRIC - time 1.00s\n",
      "2025-06-17T07:00:23.244485+0000 | compress | METRIC - error 6350.40\n",
      "2025-06-17T07:00:23.245308+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T07:00:23.245679+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T07:00:23.246086+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T07:00:23.246494+0000 | compress | METRIC - GPU 3 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T07:00:23.246913+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T07:00:23.247953+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.21.self_attn.k_proj using 512 samples\n",
      "2025-06-17T07:00:24.241940+0000 | compress | METRIC - time 0.99s\n",
      "2025-06-17T07:00:24.243078+0000 | compress | METRIC - error 2215.37\n",
      "2025-06-17T07:00:24.244073+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T07:00:24.244507+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T07:00:24.244883+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T07:00:24.245300+0000 | compress | METRIC - GPU 3 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T07:00:24.245784+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T07:00:24.246905+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.21.self_attn.v_proj using 512 samples\n",
      "2025-06-17T07:00:25.222091+0000 | compress | METRIC - time 0.97s\n",
      "2025-06-17T07:00:25.223008+0000 | compress | METRIC - error 745.75\n",
      "2025-06-17T07:00:25.223878+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T07:00:25.224241+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T07:00:25.224660+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T07:00:25.225079+0000 | compress | METRIC - GPU 3 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T07:00:25.225537+0000 | compress | METRIC - Compressed module size: 1.060864 MB\n",
      "2025-06-17T07:00:25.226677+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.21.self_attn.o_proj using 512 samples\n",
      "2025-06-17T07:00:26.213178+0000 | compress | METRIC - time 0.99s\n",
      "2025-06-17T07:00:26.214093+0000 | compress | METRIC - error 278.31\n",
      "2025-06-17T07:00:26.214945+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T07:00:26.215470+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T07:00:26.215991+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T07:00:26.216536+0000 | compress | METRIC - GPU 3 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T07:00:26.216905+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-06-17T07:00:26.217767+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.21.mlp.gate_proj using 512 samples\n",
      "2025-06-17T07:00:27.219156+0000 | compress | METRIC - time 1.00s\n",
      "2025-06-17T07:00:27.220084+0000 | compress | METRIC - error 17045.23\n",
      "2025-06-17T07:00:27.220948+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T07:00:27.221249+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T07:00:27.221671+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T07:00:27.222076+0000 | compress | METRIC - GPU 3 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T07:00:27.222508+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T07:00:27.223655+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.21.mlp.up_proj using 512 samples\n",
      "2025-06-17T07:00:28.226246+0000 | compress | METRIC - time 1.00s\n",
      "2025-06-17T07:00:28.227163+0000 | compress | METRIC - error 10788.34\n",
      "2025-06-17T07:00:28.228007+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T07:00:28.228331+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T07:00:28.228777+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T07:00:28.229146+0000 | compress | METRIC - GPU 3 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T07:00:28.229580+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n",
      "2025-06-17T07:00:28.230757+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.21.mlp.down_proj using 512 samples\n",
      "2025-06-17T07:00:30.989310+0000 | compress | METRIC - time 2.76s\n",
      "2025-06-17T07:00:30.990773+0000 | compress | METRIC - error 2289.81\n",
      "2025-06-17T07:00:30.991605+0000 | compress | METRIC - GPU 0 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T07:00:30.992204+0000 | compress | METRIC - GPU 1 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T07:00:30.992619+0000 | compress | METRIC - GPU 2 | usage: 12.17% | total memory: 24 GB\n",
      "2025-06-17T07:00:30.993009+0000 | compress | METRIC - GPU 3 | usage: 11.04% | total memory: 24 GB\n",
      "2025-06-17T07:00:30.993500+0000 | compress | METRIC - Compressed module size: 23.339008 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(22/23): Propagating: 100%|██████████| 512/512 [00:02<00:00, 176.11it/s]\n",
      "(23/23): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 292.40it/s]\n",
      "(23/23): Propagating: 100%|██████████| 512/512 [00:01<00:00, 292.62it/s]\n",
      "manager stage: Modifiers initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T07:00:37.414273+0000 | initialize | INFO - Compression lifecycle initialized for 1 modifiers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manager stage: Modifiers finalized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T07:00:37.415971+0000 | finalize | INFO - Compression lifecycle finalized for 1 modifiers\n",
      "2025-06-17T07:00:37.416480+0000 | post_process | WARNING - Optimized model is not saved. To save, please provide`output_dir` as input arg.Ex. `oneshot(..., output_dir=...)`\n"
     ]
    }
   ],
   "source": [
    "# oneshot modifies model in-place, so reload\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, device_map=\"auto\", torch_dtype=\"auto\"\n",
    ")\n",
    "# run oneshot again, with dataset\n",
    "model = oneshot(\n",
    "    model=model,\n",
    "    dataset=ds,\n",
    "    recipe=recipe,\n",
    "    max_seq_length=max_sequence_length,\n",
    "    num_calibration_samples=num_calibration_samples,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T07:00:37.424784+0000 | save_pretrained_wrapper | INFO - Fetching state_dict - this may take some time\n",
      "2025-06-17T07:00:39.437497+0000 | save_pretrained_wrapper | INFO - Fetching compressor\n",
      "2025-06-17T07:00:39.438306+0000 | get_model_compressor | INFO - skip_sparsity_compression_stats set to True. Skipping sparsity compression statistic calculations. No sparsity compressor will be applied.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Quantized Compression: 100%|██████████| 509/509 [00:04<00:00, 107.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17T07:00:44.172957+0000 | save_pretrained_wrapper | INFO - Saving compressed model to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Save model and tokenizer\n",
    "model_dir = \"./\" + model_id.split(\"/\")[-1] + \"-GPTQ-W4A16\"\n",
    "model.save_pretrained(model_dir)\n",
    "tokenizer.save_pretrained(model_dir);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4\\) Rerun `lm_eval`\n",
    "\n",
    "Note that perplexity score has improved (lower is better) for this `TinyLlama` model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-17 07:00:45 [config.py:793] This model supports multiple tasks: {'score', 'embed', 'generate', 'reward', 'classify'}. Defaulting to 'generate'.\n",
      "INFO 06-17 07:00:45 [config.py:2118] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "INFO 06-17 07:00:50 [__init__.py:243] Automatically detected platform cuda.\n",
      "INFO 06-17 07:00:53 [core.py:438] Waiting for init message from front-end.\n",
      "INFO 06-17 07:00:53 [__init__.py:31] Available plugins for group vllm.general_plugins:\n",
      "INFO 06-17 07:00:53 [__init__.py:33] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver\n",
      "INFO 06-17 07:00:53 [__init__.py:36] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.\n",
      "INFO 06-17 07:00:53 [core.py:65] Initializing a V1 LLM engine (v0.9.0.1) with config: model='./TinyLlama-1.1B-Chat-v1.0-GPTQ-W4A16', speculative_config=None, tokenizer='./TinyLlama-1.1B-Chat-v1.0-GPTQ-W4A16', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=compressed-tensors, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=1234, served_model_name=./TinyLlama-1.1B-Chat-v1.0-GPTQ-W4A16, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\": 3, \"custom_ops\": [\"none\"], \"splitting_ops\": [\"vllm.unified_attention\", \"vllm.unified_attention_with_output\"], \"compile_sizes\": [], \"inductor_compile_config\": {\"enable_auto_functionalized_v2\": false}, \"use_cudagraph\": true, \"cudagraph_num_of_warmups\": 1, \"cudagraph_capture_sizes\": [512, 504, 496, 488, 480, 472, 464, 456, 448, 440, 432, 424, 416, 408, 400, 392, 384, 376, 368, 360, 352, 344, 336, 328, 320, 312, 304, 296, 288, 280, 272, 264, 256, 248, 240, 232, 224, 216, 208, 200, 192, 184, 176, 168, 160, 152, 144, 136, 128, 120, 112, 104, 96, 88, 80, 72, 64, 56, 48, 40, 32, 24, 16, 8, 4, 2, 1], \"max_capture_size\": 512}\n",
      "WARNING 06-17 07:00:54 [utils.py:2671] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f5b16fbd6d0>\n",
      "INFO 06-17 07:00:54 [parallel_state.py:1064] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "WARNING 06-17 07:00:54 [topk_topp_sampler.py:58] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 06-17 07:00:54 [gpu_model_runner.py:1531] Starting to load model ./TinyLlama-1.1B-Chat-v1.0-GPTQ-W4A16...\n",
      "INFO 06-17 07:00:54 [compressed_tensors_wNa16.py:94] Using MarlinLinearKernel for CompressedTensorsWNA16\n",
      "INFO 06-17 07:00:54 [cuda.py:217] Using Flash Attention backend on V1 engine.\n",
      "INFO 06-17 07:00:54 [backends.py:35] Using InductorAdaptor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.37it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.37it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-17 07:00:54 [default_loader.py:280] Loading weights took 0.22 seconds\n",
      "INFO 06-17 07:00:55 [gpu_model_runner.py:1549] Model loading took 0.7432 GiB and 0.488780 seconds\n",
      "INFO 06-17 07:01:01 [backends.py:459] Using cache directory: /opt/app-root/src/.cache/vllm/torch_compile_cache/f2259db575/rank_0_0 for vLLM's torch.compile\n",
      "INFO 06-17 07:01:01 [backends.py:469] Dynamo bytecode transform time: 6.70 s\n",
      "INFO 06-17 07:01:04 [backends.py:158] Cache the graph of shape None for later use\n",
      "INFO 06-17 07:01:26 [backends.py:170] Compiling a graph for general shape takes 23.90 s\n",
      "INFO 06-17 07:01:38 [monitor.py:33] torch.compile takes 30.61 s in total\n",
      "INFO 06-17 07:01:39 [kv_cache_utils.py:637] GPU KV cache size: 813,920 tokens\n",
      "INFO 06-17 07:01:39 [kv_cache_utils.py:640] Maximum concurrency for 2,048 tokens per request: 397.42x\n",
      "INFO 06-17 07:02:01 [gpu_model_runner.py:1933] Graph capturing finished in 22 secs, took 0.37 GiB\n",
      "INFO 06-17 07:02:01 [core.py:167] init engine (profile, create kv cache, warmup model) took 66.74 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
      "[Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "[Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
      "[Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "[Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte\n",
      "[Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "100%|██████████| 62/62 [00:00<00:00, 710.87it/s]\n",
      "  0%|          | 0/62 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (5945 > 2048). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 62/62 [00:00<00:00, 100.49it/s]\n",
      "Running loglikelihood requests:   0%|          | 0/62 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d4137bfb1a492f8f5027c5be497c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "810efd8f3e354feeaf2f9749356453e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/62 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running loglikelihood requests: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]\n",
      "Running loglikelihood requests:   0%|          | 0/62 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa183ddb98f84cc1b326bc395bc97cf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb4408ca9c88411483222ae2eae2028c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/62 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running loglikelihood requests: 100%|██████████| 62/62 [00:05<00:00, 10.89it/s]\n",
      "Running loglikelihood requests:   0%|          | 0/62 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4617cb3785342d4b231e0378a52ebdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ff4334a88c4497a0c695fdf41fe3b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/62 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running loglikelihood requests: 100%|██████████| 62/62 [00:05<00:00, 10.46it/s]\n",
      "[rank0]:[W617 07:02:35.790416464 ProcessGroupNCCL.cpp:1476] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    }
   ],
   "source": [
    "results = lm_eval.simple_evaluate(\n",
    "    model=\"vllm\" if use_gpu else \"hf\",\n",
    "    model_args={\n",
    "        \"pretrained\": model_dir,\n",
    "        \"add_bos_token\": True,\n",
    "        \"device\": \"auto\"\n",
    "    },\n",
    "    tasks=[\"wikitext\"],\n",
    "    batch_size=\"auto\" if use_gpu else 4,\n",
    "    limit=None if use_gpu else 4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Tasks  |Version|Filter|n-shot|    Metric     |   | Value |   |Stderr|\n",
      "|--------|------:|------|-----:|---------------|---|------:|---|------|\n",
      "|wikitext|      2|none  |     0|bits_per_byte  |↓  | 0.7508|±  |   N/A|\n",
      "|        |       |none  |     0|byte_perplexity|↓  | 1.6827|±  |   N/A|\n",
      "|        |       |none  |     0|word_perplexity|↓  |16.1636|±  |   N/A|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(make_table(results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
